{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Triple_XLNet_QUEST_exp",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "56afzfMr8JM-"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh-fIA0HFIum"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRMy__hYxGLa"
      },
      "source": [
        "# Load modified XLNet model with mem backprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7sU4sTTyYvX"
      },
      "source": [
        "#@title gist link to modified XLNet code\n",
        "#@markdown - modify XLNetModel.cache_mem function in /transformers/models/xlnet/modeling_xlnet.py that it does not detach the mem states.\n",
        "\n",
        "gist_path = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxMk7K9gph4c"
      },
      "source": [
        "!git clone $gist_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUEG13qrpxea"
      },
      "source": [
        "mod_file_path = input(\"where is the modified modeling_xlnet.py saved?\")\n",
        "!cp -f $mod_file_path /usr/local/lib/python3.7/dist-packages/transformers/models/xlnet/modeling_xlnet.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP_8AgLFovMG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5PG-k2z1ta"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rcfDQAHo6bJ"
      },
      "source": [
        "df_train = pd.read_csv(input('Path to train.csv: '))\n",
        "df_test = pd.read_csv(input('Path to test.csv: '))\n",
        "df_submit = pd.read_csv(input('Path to submission.csv: '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-igtJcusZ9X"
      },
      "source": [
        "df_train.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQQkafbrM9KT"
      },
      "source": [
        "target_cols = ['question_asker_intent_understanding',\n",
        "       'question_body_critical', 'question_conversational',\n",
        "       'question_expect_short_answer', 'question_fact_seeking',\n",
        "       'question_has_commonly_accepted_answer',\n",
        "       'question_interestingness_others', 'question_interestingness_self',\n",
        "       'question_multi_intent', 'question_not_really_a_question',\n",
        "       'question_opinion_seeking', 'question_type_choice',\n",
        "       'question_type_compare', 'question_type_consequence',\n",
        "       'question_type_definition', 'question_type_entity',\n",
        "       'question_type_instructions', 'question_type_procedure',\n",
        "       'question_type_reason_explanation', 'question_type_spelling',\n",
        "       'question_well_written', 'answer_helpful',\n",
        "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
        "       'answer_satisfaction', 'answer_type_instructions',\n",
        "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
        "       'answer_well_written']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs4Cxdqc2zFJ"
      },
      "source": [
        "input_cols = ['question_title', 'question_body', 'answer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zypc9q0Mhi2"
      },
      "source": [
        "plt.figure()\n",
        "fig, ax = plt.subplots(figsize=(20, 10));\n",
        "df_train[target_cols].hist(ax=ax);\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUA4gNRSWMeU"
      },
      "source": [
        "# Preprocess the text data\n",
        " - Define Dataset class\n",
        " - use the html library to undo the escapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTEQ6GmGmJS"
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "from torch import nn\n",
        "from transformers import XLNetModel, RobertaModel\n",
        "from transformers import XLNetPreTrainedModel\n",
        "from transformers.models.roberta.modeling_roberta import *\n",
        "from transformers import get_linear_schedule_with_warmup, RobertaTokenizer, XLNetTokenizer, AdamW\n",
        "from transformers.modeling_utils import SequenceSummary\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\", do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf_yYrn-6z2t"
      },
      "source": [
        "import html\n",
        "t_len = []\n",
        "q_len = []\n",
        "a_len = []\n",
        "for i, (t, q, a) in df_test[input_cols].iterrows():\n",
        "    t, q, a = html.unescape(t), html.unescape(q), html.unescape(a)\n",
        "    t = tokenizer.tokenize(t)\n",
        "    q = tokenizer.tokenize(q)\n",
        "    a = tokenizer.tokenize(a)\n",
        "    t_len.append(len(t))\n",
        "    q_len.append(len(q))\n",
        "    a_len.append(len(a))\n",
        "print(np.mean(t_len), np.mean(q_len), np.mean(a_len))\n",
        "print(np.percentile(t_len, 90), np.percentile(q_len, 90), np.percentile(a_len, 90))\n",
        "print(min(t_len), min(q_len), min(a_len))\n",
        "print(max(t_len), max(q_len), max(a_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu__eBDb1yfD"
      },
      "source": [
        "def pad_seq(seq, pad_id, total_length):\n",
        "    pad_len = total_length - len(seq)\n",
        "    return {'seq': seq + ([pad_id] * pad_len),\n",
        "            'mask': ([1] * len(seq)) + ([0] * pad_len)}\n",
        "\n",
        "def prepad_seq(seq, pad_id, total_length):\n",
        "    pad_len = total_length - len(seq)\n",
        "    return {'seq': ([pad_id] * pad_len) + seq,\n",
        "            'mask': ([0] * pad_len) + ([1] * len(seq))}\n",
        "\n",
        "\n",
        "import html\n",
        "class QUEST_XLNet_Seg_Dataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_lens, device='cpu', total_pad = 512, input_cols=input_cols, target_cols=target_cols, training=True, half=False):\n",
        "        self.df = df\n",
        "        self.input_cols = input_cols\n",
        "        self.target_cols = target_cols\n",
        "        self.is_training = training\n",
        "        self.max_lens = max_lens\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.total_pad = total_pad\n",
        "        self.half = half\n",
        "\n",
        "    def collate_fn(self, data):\n",
        "        batched = {}\n",
        "        float_type = torch.float32\n",
        "        if self.half:\n",
        "            float_type = torch.float16\n",
        "        for input_col in self.input_cols:\n",
        "            batched[input_col] = {}\n",
        "            collate_seq = []\n",
        "            collate_mask = []\n",
        "            max_len = 0\n",
        "            for x in data:\n",
        "                max_len = max(max_len, len(x[input_col]))\n",
        "            for x in data:\n",
        "                padded_info = prepad_seq(x[input_col],\n",
        "                                         self.tokenizer.pad_token_id,\n",
        "                                         max_len)\n",
        "                collate_seq.append(padded_info['seq'])\n",
        "                collate_mask.append(padded_info['mask'])\n",
        "            batched[input_col]['seq'] = torch.tensor(collate_seq, dtype=torch.long).to(self.device)\n",
        "\n",
        "            batched[input_col]['mask'] = torch.tensor(collate_mask, dtype=float_type).to(self.device)\n",
        "        \n",
        "        targets = [x['target'] for x in data]\n",
        "        batched['target'] = torch.tensor(targets, dtype=float_type).to(self.device)\n",
        "\n",
        "        return batched\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        rtn = {}\n",
        "        for i, (input_col, max_len) in enumerate(zip(self.input_cols, self.max_lens)):\n",
        "            col_val = self.df[input_col].iloc[idx]\n",
        "            col_val = html.unescape(col_val)\n",
        "            token_info = self.tokenizer(col_val, add_special_tokens=False)\n",
        "            token_ids = token_info['input_ids']\n",
        "            rtn[input_col] = token_ids[:max_len - 2] + [self.tokenizer.sep_token_id, self.tokenizer.cls_token_id]\n",
        "        if self.is_training:\n",
        "            target_vals = self.df[self.target_cols].iloc[idx].tolist()\n",
        "            rtn['target'] = target_vals\n",
        "        return rtn\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e5OJXNNYl2L"
      },
      "source": [
        "demo_dataset = QUEST_XLNet_Seg_Dataset(df_train, tokenizer, [64, 512, 512])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwU7ni3DbHVm"
      },
      "source": [
        "demo_data_loader = DataLoader(dataset=demo_dataset, batch_size=8, shuffle=True, collate_fn=demo_dataset.collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djmm_h0O0TVY"
      },
      "source": [
        "# Define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Mfh7gwrb2L"
      },
      "source": [
        "Just forward passing experiment...\n",
        "\n",
        "```python\n",
        "xlnet_1 = XLNetModel.from_pretrained(\"xlnet-base-cased\", use_mems_train=True).to('cuda')\n",
        "xlnet_2 = XLNetModel.from_pretrained(\"xlnet-base-cased\", use_mems_train=True).to('cuda')\n",
        "xlnet_3 = XLNetModel.from_pretrained(\"xlnet-base-cased\", use_mems_train=True).to('cuda')\n",
        "logit_maker = nn.Linear(768 * 3, 30).to('cuda')\n",
        "\n",
        "input1 = torch.randint(low=0, high=200, size=(8, 64)).to('cuda')\n",
        "mask1 = torch.randint(low=0, high=2, size=(8, 64)).to('cuda')\n",
        "xlnet_out1 = xlnet_1(input_ids=input1,\n",
        "                        attention_mask=mask1)\n",
        "xlnet_cls1 = xlnet_out1.last_hidden_state[:, -1, :]\n",
        "xlnet_mem1 = xlnet_out1.mems\n",
        "input2 = torch.randint(low=0, high=200, size=(8, 512)).to('cuda')\n",
        "mask2 = torch.randint(low=0, high=2, size=(8, 512)).to('cuda')\n",
        "xlnet_out2 = xlnet_2(input_ids=input2,\n",
        "                        attention_mask=mask2,\n",
        "                        mem=xlnet_mem1)\n",
        "x1net_cls2 = xlnet_out2.last_hidden_state[:, -1, :]\n",
        "xlnet_mem2 = xlnet_out2.mems\n",
        "input3 = torch.randint(low=0, high=200, size=(8, 512)).to('cuda')\n",
        "mask3 = torch.randint(low=0, high=2, size=(8, 512)).to('cuda')\n",
        "xlnet_out3 = xlnet_3(input_ids=input3,\n",
        "                        attention_mask=mask3,\n",
        "                        mem=xlnet_mem2)\n",
        "x1net_cls3 = xlnet_out3.last_hidden_state[:, -1, :]\n",
        "cls_unified = torch.cat([xlnet_cls1, x1net_cls2, x1net_cls3],dim=1)\n",
        "print(cls_unified.size())\n",
        "logits = logit_maker(cls_unified)\n",
        "print(logits.size())\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOHZpWxBf9o0"
      },
      "source": [
        " from collections import namedtuple\n",
        "class XLNetForSequenceRegressionPyramid(nn.Module):\n",
        "    def __init__(self, num_labels=30):\n",
        "        super(XLNetForSequenceRegressionPyramid, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.xlnet_t = XLNetModel.from_pretrained(\"xlnet-base-cased\", use_mems_train=True)\n",
        "        self.xlnet_q = XLNetModel.from_pretrained(\"xlnet-base-cased\", use_mems_train=True)\n",
        "        self.xlnet_a = XLNetModel.from_pretrained(\"xlnet-base-cased\", use_mems_train=True)\n",
        "        hidden_dim = self.xlnet_a.d_model\n",
        "        self.hidden_dim = hidden_dim\n",
        "        num_layers = self.xlnet_a.n_layer\n",
        "        self.dense_states = nn.Linear(num_layers * hidden_dim, hidden_dim)\n",
        "        self.dense_1 = nn.Linear(hidden_dim * 6, hidden_dim)\n",
        "        self.dense_2 = nn.Linear(hidden_dim, num_labels)\n",
        "        self.activation = nn.ELU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.seq_dropout = nn.Dropout(0.1)\n",
        "        self.loss_fct = nn.BCEWithLogitsLoss()\n",
        "        self.SequenceRegressorOutput = namedtuple('SequenceRegressorOutput',\n",
        "                                             ['loss', 'logits', 'hidden_states', 'attentions'])\n",
        "    \n",
        "    def forward(self, seq_t, mask_t, seq_q, mask_q, seq_a, mask_a, labels=None):\n",
        "        xlnet_out_t = self.xlnet_t(input_ids=seq_t,\n",
        "                                attention_mask=mask_t)\n",
        "        xlnet_cls_t = xlnet_out_t.last_hidden_state[:, -1, :]\n",
        "        dropped_mask_t = self.seq_dropout(mask_t)\n",
        "        xlnet_sum_t = torch.sum(xlnet_out_t.last_hidden_state * dropped_mask_t.unsqueeze(2).expand(-1, -1, self.hidden_dim), 1)\n",
        "        mask_sum_t = dropped_mask_t.sum(1)\n",
        "        mask_sum_t[mask_sum_t==0] = 1.0\n",
        "        # print(mask_sum_t.size())\n",
        "        # print(xlnet_sum_t.size())\n",
        "        xlnet_avg_t = xlnet_sum_t / mask_sum_t.unsqueeze(1).expand(-1, self.hidden_dim)\n",
        "        xlnet_mem_t = xlnet_out_t.mems\n",
        "\n",
        "        xlnet_out_q = self.xlnet_q(input_ids=seq_q,\n",
        "                                attention_mask=mask_q,\n",
        "                                mem=xlnet_mem_t)\n",
        "        xlnet_cls_q = xlnet_out_q.last_hidden_state[:, -1, :]\n",
        "        dropped_mask_q = self.seq_dropout(mask_q)\n",
        "        xlnet_sum_q = torch.sum(xlnet_out_q.last_hidden_state * dropped_mask_q.unsqueeze(2).expand(-1, -1, self.hidden_dim), 1)\n",
        "        mask_sum_q = dropped_mask_q.sum(1)\n",
        "        mask_sum_q[mask_sum_q==0] = 1.0\n",
        "        xlnet_avg_q = xlnet_sum_q / mask_sum_q.unsqueeze(1).expand(-1, self.hidden_dim)\n",
        "        xlnet_mem_q = xlnet_out_q.mems\n",
        "        \n",
        "        xlnet_out_a = self.xlnet_a(input_ids=seq_a,\n",
        "                                attention_mask=mask_a,\n",
        "                                mem=xlnet_mem_q)\n",
        "        xlnet_cls_a = xlnet_out_a.last_hidden_state[:, -1, :]\n",
        "        dropped_mask_a = self.seq_dropout(mask_a)\n",
        "        xlnet_sum_a = torch.sum(xlnet_out_a.last_hidden_state * dropped_mask_a.unsqueeze(2).expand(-1, -1, self.hidden_dim), 1)\n",
        "        mask_sum_a = dropped_mask_a.sum(1)\n",
        "        mask_sum_a[mask_sum_a==0] = 1.0\n",
        "        xlnet_avg_a = xlnet_sum_a / mask_sum_a.unsqueeze(1).expand(-1, self.hidden_dim)\n",
        "\n",
        "\n",
        "        # xlnet_mem_a = xlnet_out_t.mems\n",
        "        cls_unified = torch.cat([xlnet_cls_t,\n",
        "                                 xlnet_avg_t,\n",
        "                                 xlnet_cls_q,\n",
        "                                 xlnet_avg_q,\n",
        "                                 xlnet_cls_a,\n",
        "                                 xlnet_avg_a], dim=1)\n",
        "        # states_unified = torch.cat([layer[-1] for layer in xlnet_mem_a], dim=1)\n",
        "\n",
        "        x_cls = self.dense_1(cls_unified)\n",
        "        # x_states = self.dense_states(states_unified)\n",
        "        # x = torch.cat((x_cls, x_states), dim=1)\n",
        "\n",
        "        x = x_cls\n",
        "        \n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        # print(x.size())\n",
        "        logits = self.dense_2(x)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fct(logits, labels)        \n",
        "        return self.SequenceRegressorOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=xlnet_out_a.hidden_states,\n",
        "            attentions=xlnet_out_a.attentions,\n",
        "        )\n",
        "    \n",
        "    def get_encoder_classifier_params(self):\n",
        "        xlnet_param_names = ['xlnet_t', 'xlnet_q', 'xlnet_a']\n",
        "        xlnet_named_params = list(filter(lambda kv: any(key in kv[0] for key in xlnet_param_names), self.named_parameters()))\n",
        "        classifier_named_params = list(filter(lambda kv: not any(key in kv[0] for key in xlnet_param_names), self.named_parameters()))\n",
        "        xlnet_params = [e[1] for e in xlnet_named_params]\n",
        "        classifier_params = [e[1] for e in classifier_named_params]\n",
        "        return {'encoder_params':xlnet_params,\n",
        "                \"classifier_params\":classifier_params}\n",
        "    \n",
        "    def get_device(self):\n",
        "        # getting the device based on the title encoder...\n",
        "        return self.xlnet_t.word_embedding.weight.device\n",
        "\n",
        "    def freeze_title_encoder(self):\n",
        "        for param in self.xlnet_t.parameters():\n",
        "            param.requires_grad=False\n",
        "    \n",
        "    def freeze_question_encoder(self):\n",
        "        for param in self.xlnet_q.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo4hD2dE0Xvr"
      },
      "source": [
        "# Define utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caaxlqjqZzne"
      },
      "source": [
        "from scipy.stats import spearmanr\n",
        "def compute_spearman(y_true, y_pred):\n",
        "    col = y_true.shape[1]\n",
        "    lst = []\n",
        "    y_true = np.round(y_true, 6)\n",
        "    y_pred = np.round(y_pred, 6)\n",
        "    for i in range(col):\n",
        "        # p = round(spearmanr(y_true[:, i], y_pred[:, i])[0], 5)\n",
        "        p = spearmanr(y_true[:, i] + np.random.normal(0, 1e-7, y_pred[:, i].shape[0]),\n",
        "                        y_pred[:, i] + np.random.normal(0, 1e-7, y_pred[:, i].shape[0])).correlation\n",
        "        if np.isnan(p):\n",
        "            p = spearmanr(y_true[:, i] + np.random.normal(0, 1e-7, y_pred[:, i].shape[0]),\n",
        "                        y_pred[:, i] + np.random.normal(0, 1e-7, y_pred[:, i].shape[0])).correlation\n",
        "        lst.append(p)\n",
        "    # print(lst)\n",
        "    return np.array(lst), sum(lst)/len(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq-l9YdbvvGd"
      },
      "source": [
        "import gc\n",
        "def clear_mem(model_name='model'):\n",
        "    if model_name in locals():\n",
        "        print('deleting model...')\n",
        "        del model\n",
        "    for x in list(globals().keys()):\n",
        "        variable = eval(x)\n",
        "        if torch.is_tensor(variable) and variable.is_cuda:\n",
        "            print(x)\n",
        "            del variable\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-30GYfVO6QU"
      },
      "source": [
        "clear_mem()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGMEtZPr0bnT"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKRlTJf8yPUx"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import tqdm.notebook as tqdm\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "\n",
        "def fold_train(model, train_dataset, valid_dataset, optimizer, max_epoch,\n",
        "               batch_schedule=[4, 2, 1], lr_decay=0.1, clip=50.0, patience=2):\n",
        "    bi = 0\n",
        "    valid_data_loader = DataLoader(dataset=valid_dataset, batch_size=batch_schedule[0],\n",
        "                                   shuffle=False, collate_fn=valid_dataset.collate_fn)\n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,patience=2, factor=lr_decay,verbose=True)\n",
        "    best_avg_valid_loss = float('inf')\n",
        "    best_spearmanr = float('-inf')\n",
        "    patience_count = patience\n",
        "    for epoch in tqdm.trange(max_epoch, desc=\"training\", unit=\"epoch\"):\n",
        "        total_loss = 0.0\n",
        "        final_avg_loss = 0.0\n",
        "        train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_schedule[bi],\n",
        "                                       shuffle=True, collate_fn=train_dataset.collate_fn)\n",
        "        with tqdm.tqdm(train_data_loader,desc=\"epoch {} train\".format(epoch + 1),\n",
        "                  unit=\"batch\",total=len(train_data_loader)) as train_batch_iterator:\n",
        "            model.train()\n",
        "            for i, batch_data in enumerate(train_batch_iterator, start=1):\n",
        "                optimizer.zero_grad()\n",
        "                loss_data = model(seq_t=batch_data['question_title']['seq'],\n",
        "                                  mask_t=batch_data['question_title']['mask'],\n",
        "                                  seq_q=batch_data['question_body']['seq'],\n",
        "                                  mask_q=batch_data['question_body']['mask'],\n",
        "                                  seq_a=batch_data['answer']['seq'],\n",
        "                                  mask_a=batch_data['answer']['mask'],\n",
        "                                  labels=batch_data['target'])\n",
        "                loss = loss_data.loss\n",
        "                total_loss += loss.item()\n",
        "                loss.backward()\n",
        "                # _ = nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "                optimizer.step()\n",
        "                train_batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item())\n",
        "                final_avg_loss = total_loss / i\n",
        "            scheduler.step(final_avg_loss)\n",
        "        total_valid_loss = 0.0\n",
        "        final_avg_valid_loss = 0.0\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            with tqdm.tqdm(valid_data_loader,desc=\"epoch {} valid\".format(epoch + 1),\n",
        "                      unit=\"batch\",total=len(valid_data_loader),leave=False) as valid_batch_iterator:\n",
        "                \n",
        "                for i, batch_data in enumerate(valid_batch_iterator, start=1):\n",
        "                    loss_data = model(seq_t=batch_data['question_title']['seq'],\n",
        "                                      mask_t=batch_data['question_title']['mask'],\n",
        "                                      seq_q=batch_data['question_body']['seq'],\n",
        "                                      mask_q=batch_data['question_body']['mask'],\n",
        "                                      seq_a=batch_data['answer']['seq'],\n",
        "                                      mask_a=batch_data['answer']['mask'],\n",
        "                                      labels=batch_data['target'])\n",
        "                    loss = loss_data.loss\n",
        "                    total_valid_loss += loss.item()\n",
        "                    valid_batch_iterator.set_postfix(mean_loss=total_valid_loss / i, current_loss=loss.item())\n",
        "                    final_avg_valid_loss = total_valid_loss / i\n",
        "                    pred_labels.append(loss_data.logits.sigmoid().to('cpu').numpy())\n",
        "                    true_labels.append(batch_data['target'].to('cpu').numpy())\n",
        "        true_labels = np.concatenate(true_labels, axis=0)\n",
        "        pred_labels = np.concatenate(pred_labels, axis=0)\n",
        "        sp_correlation = compute_spearman(pred_labels, true_labels)\n",
        "        \n",
        "        np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "        print(\"spearmanr scores:\", sp_correlation[0])\n",
        "        sorted_ind = np.argsort(sp_correlation[0])\n",
        "        sorted_labels = [target_cols[ind] for ind in sorted_ind]\n",
        "        print(\"predicted features from worst to best:\")\n",
        "        for r, (lb,sc) in enumerate(zip(sorted_labels, sp_correlation[0][sorted_ind])):\n",
        "            print(f\"\\t{r}. {lb}: {sc}\")\n",
        "        np.set_printoptions()\n",
        "        \n",
        "        print(f\"Validation results for epoch #{epoch + 1}: average_loss={final_avg_valid_loss}, spearman_rho={sp_correlation[-1]}\")\n",
        "        if sp_correlation[-1] < best_spearmanr:\n",
        "            patience_count -= 1\n",
        "        elif sp_correlation[-1] > best_spearmanr:\n",
        "            # filepath = f\"./best_fold{fold_num}.pt\"\n",
        "            print(\"Saving this model...\")\n",
        "            # filepath, best_model_info = save_model(model, filepath,\n",
        "            #                                        avg_valid_loss=final_avg_valid_loss,\n",
        "            #                                        spearmanr_corr=sp_correlation[-1])\n",
        "            \n",
        "        best_spearmanr = max(sp_correlation[-1], best_spearmanr)\n",
        "        if patience_count == 0:\n",
        "            print(\"Early Stopping: the average spearmanr did not improve.\")\n",
        "            break\n",
        "\n",
        "n_fold=6\n",
        "\n",
        "kf = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
        "max_epoch = 30\n",
        "fold_num = 1\n",
        "batch_size = 4\n",
        "for train_index, valid_index in tqdm.tqdm(kf.split(df_train), desc=\"Cross Validation\", unit=\"fold\", total=n_fold):\n",
        "    print('Fold {} starting...'.format(fold_num))\n",
        "    clear_mem()\n",
        "    model = XLNetForSequenceRegressionPyramid()\n",
        "    # model.half()\n",
        "    # model.unfreeze_decoder()\n",
        "    model = model.cuda()\n",
        "    # model.freeze_decoder()\n",
        "    device_used = model.get_device()\n",
        "    # model.freeze_title_encoder()\n",
        "    # model.freeze_question_encoder()\n",
        "    train_dataset = QUEST_XLNet_Seg_Dataset(df_train.iloc[train_index], tokenizer, [64, 512, 512],device=device_used)\n",
        "    valid_dataset = QUEST_XLNet_Seg_Dataset(df_train.iloc[valid_index], tokenizer, [64, 512, 512], device=device_used)\n",
        "    param_dict = model.get_encoder_classifier_params()\n",
        "    xlnet_params = param_dict['encoder_params']\n",
        "    classifier_params = param_dict['classifier_params']\n",
        "    optimizer = AdamW([{'params': xlnet_params}, {'params': classifier_params, 'lr': 1e-4}], lr=2e-5, weight_decay=0.01, betas=(0.5, 0.999), correct_bias=True)\n",
        "    fold_train(model, train_dataset, valid_dataset, optimizer, max_epoch)\n",
        "    clear_mem()\n",
        "    fold_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}