{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DistilBERT_QUEST_exp",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxN_GHe_kq_B"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh-fIA0HFIum"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP_8AgLFovMG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6sOhMQOKijo"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktVoB7aqp18E"
      },
      "source": [
        "df_train = pd.read_csv(input('Path to train.csv: '))\n",
        "df_test = pd.read_csv(input('Path to test.csv: '))\n",
        "df_submit = pd.read_csv(input('Path to submission.csv: '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-igtJcusZ9X"
      },
      "source": [
        "df_train.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQQkafbrM9KT"
      },
      "source": [
        "target_cols = ['question_asker_intent_understanding',\n",
        "       'question_body_critical', 'question_conversational',\n",
        "       'question_expect_short_answer', 'question_fact_seeking',\n",
        "       'question_has_commonly_accepted_answer',\n",
        "       'question_interestingness_others', 'question_interestingness_self',\n",
        "       'question_multi_intent', 'question_not_really_a_question',\n",
        "       'question_opinion_seeking', 'question_type_choice',\n",
        "       'question_type_compare', 'question_type_consequence',\n",
        "       'question_type_definition', 'question_type_entity',\n",
        "       'question_type_instructions', 'question_type_procedure',\n",
        "       'question_type_reason_explanation', 'question_type_spelling',\n",
        "       'question_well_written', 'answer_helpful',\n",
        "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
        "       'answer_satisfaction', 'answer_type_instructions',\n",
        "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
        "       'answer_well_written']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs4Cxdqc2zFJ"
      },
      "source": [
        "input_cols = ['question_title', 'question_body', 'answer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fYq70jPKXCx"
      },
      "source": [
        "# Plot out the label distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zypc9q0Mhi2"
      },
      "source": [
        "plt.figure()\n",
        "fig, ax = plt.subplots(figsize=(20, 10));\n",
        "df_train[target_cols].hist(ax=ax);\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqpVfasFM3DQ"
      },
      "source": [
        "# Preprocess the text data\n",
        " - Define Dataset class\n",
        " - use the html library to undo the escapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTEQ6GmGmJS"
      },
      "source": [
        "#@title Model Selection\n",
        "\n",
        "import torch\n",
        "import torch.functional as F\n",
        "from torch import nn\n",
        "from transformers import DistilBertModel\n",
        "from transformers import DistilBertPreTrainedModel\n",
        "from transformers.models.bert.modeling_bert import *\n",
        "from transformers import get_linear_schedule_with_warmup, DistilBertTokenizer, AdamW\n",
        "from transformers.modeling_utils import SequenceSummary\n",
        "\n",
        "pretrained_model = \"distilbert-base-uncased\" #@param [\"distilbert-base-uncased-distilled-squad\", \"distilbert-base-cased-distilled-squad\", \"distilbert-base-uncased\"]\n",
        "\n",
        "batch_size = 16 #@param [\"16\", \"8\", \"4\", \"2\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(pretrained_model)\n",
        "tokenizer(\"Hello, my name is Cat.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed9BK8ri3RqS"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu__eBDb1yfD"
      },
      "source": [
        "import html\n",
        "class QUEST_DistilBert_Dataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_lens, device='cpu', total_pad = 512, input_cols=input_cols, target_cols=target_cols, training=True):\n",
        "        self.df = df\n",
        "        self.input_cols = input_cols\n",
        "        self.target_cols = target_cols\n",
        "        self.is_training = training\n",
        "        self.max_lens = max_lens\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.total_pad = total_pad\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        col_vals = []\n",
        "        sep_mask = []\n",
        "        seg = 1\n",
        "        for i, (input_col, max_len) in enumerate(zip(self.input_cols, self.max_lens)):\n",
        "            col_val = self.df[input_col].iloc[idx]\n",
        "            col_val = html.unescape(col_val)\n",
        "            token_info = self.tokenizer(col_val, add_special_tokens=False)\n",
        "            token_ids = token_info['input_ids'][:max_len-1]\n",
        "            if i == 0:\n",
        "                token_ids = [self.tokenizer.cls_token_id] + token_ids[:max_len-2] + [self.tokenizer.sep_token_id]\n",
        "            else:\n",
        "                token_ids = token_ids + [self.tokenizer.sep_token_id]\n",
        "            sep_mask += [seg] * len(token_ids)\n",
        "            seg += 1\n",
        "            col_vals.append(token_ids)\n",
        "\n",
        "        rtn = {}\n",
        "        if self.is_training:\n",
        "            target_vals = self.df[target_cols].iloc[idx].tolist()\n",
        "            target_vals = torch.tensor(target_vals).to(self.device )\n",
        "            rtn['target'] = target_vals\n",
        "\n",
        "        cv = []\n",
        "        mask = []\n",
        "        for val in col_vals:\n",
        "            cv += val\n",
        "            mask += [1] * len(val)\n",
        "        # if len(cv) < self.total_pad:\n",
        "        #     mask += [0] * (self.total_pad - len(cv))\n",
        "        #     sep_mask += [0] * (self.total_pad - len(cv))\n",
        "        #     cv += [self.tokenizer.pad_token_id] * (self.total_pad - len(cv))\n",
        "        rtn['input_sequence'] = torch.LongTensor(cv).to(self.device )\n",
        "        rtn['input_mask'] = torch.FloatTensor(mask).to(self.device )\n",
        "        rtn['seg_mask'] = torch.FloatTensor(sep_mask).to(self.device )\n",
        "\n",
        "        return rtn\n",
        "\n",
        "    def collate_fn(self, data):\n",
        "        input_sequences = []\n",
        "        input_masks = []\n",
        "        seg_masks = []\n",
        "        targets = []\n",
        "        col_batch = {}\n",
        "        for x in data:\n",
        "            input_sequences.append(x['input_sequence'])\n",
        "            input_masks.append(x['input_mask'])\n",
        "            seg_masks.append(x['seg_mask'])\n",
        "            if 'target' in x:\n",
        "                targets.append(x['target'])\n",
        "        col_batch['input_sequence'] = torch.nn.utils.rnn.pad_sequence(input_sequences,batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "        col_batch['input_mask'] = torch.nn.utils.rnn.pad_sequence(input_masks,batch_first=True, padding_value=0.0)\n",
        "        col_batch['seg_mask'] = torch.nn.utils.rnn.pad_sequence(seg_masks,batch_first=True, padding_value=0.0)\n",
        "        if targets:\n",
        "            col_batch['target'] = torch.stack(targets)\n",
        "        if col_batch['input_sequence'].size()[1] > self.total_pad:\n",
        "            print(\"something wrong\")\n",
        "            print(col_batch)\n",
        "        return col_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIKJxhhA-DPb"
      },
      "source": [
        "input_cols = ['question_title', 'question_body', 'answer']\n",
        "train_dataset = QUEST_DistilBert_Dataset(df_train, tokenizer, [64, 224, 224])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5q-9ejjKxqH"
      },
      "source": [
        "# Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn140MzrAJzT"
      },
      "source": [
        " from collections import namedtuple\n",
        " class DistilBertRegressionHead(nn.Module):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, hidden_dropout_prob, num_labels):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
        "        self.out_proj = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        # x = x[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
        "        # x = torch.mean(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense(x)\n",
        "        # x = torch.tanh(x)\n",
        "        x = torch.tanh(x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.out_proj(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "class DistilBertForSequenceRegression(DistilBertPreTrainedModel):\n",
        "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
        "\n",
        "    def __init__(self, config, num_labels=30, cls_id=tokenizer.cls_token_id, sep_id=tokenizer.sep_token_id):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.distilbert = DistilBertModel(config)\n",
        "        self.regressor = DistilBertRegressionHead(config.dim * 4,\n",
        "                                               config.seq_classif_dropout,\n",
        "                                               num_labels)\n",
        "        self.cls_id = cls_id\n",
        "        self.sep_id = sep_id\n",
        "        self.d_model = config.dim\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        seg_masks=None,\n",
        "        output_attentions=True,\n",
        "        output_hidden_states=True,\n",
        "        return_dict=True,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
        "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
        "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        cls_position = torch.where(input_ids==self.cls_id)\n",
        "        # sep_position = torch.where(input_ids==self.sep_id)\n",
        "        assert cls_position[1].size()[0] == input_ids.size()[0], \"Some of the instances are missing cls token!\"\n",
        "        assert torch.unique(cls_position[0]).size()[0] == input_ids.size()[0], \"Some of the instances are missing cls token!\"\n",
        "        outputs = self.distilbert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        cls_output = sequence_output[cls_position]\n",
        "\n",
        "        # perform avg pooling across t q a\n",
        "        t_mask = torch.where(seg_masks==1, 1.0, 0.0)\n",
        "        t_sum_pool = torch.sum(sequence_output * t_mask.unsqueeze(2).expand(-1, -1, self.d_model), 1)\n",
        "        t_mask_sum = t_sum_pool.sum(1)\n",
        "        t_mask_sum[t_mask_sum==0.0] = 1.0\n",
        "        t_avgpool = t_sum_pool / t_mask_sum.unsqueeze(1).expand(-1, self.d_model)\n",
        "\n",
        "        q_mask = torch.where(seg_masks==2, 1.0, 0.0)\n",
        "        q_sum_pool = torch.sum(sequence_output * q_mask.unsqueeze(2).expand(-1, -1, self.d_model), 1)\n",
        "        q_mask_sum = q_sum_pool.sum(1)\n",
        "        q_mask_sum[q_mask_sum==0.0] = 1.0\n",
        "        q_avgpool = q_sum_pool / q_mask_sum.unsqueeze(1).expand(-1, self.d_model)\n",
        "\n",
        "        a_mask = torch.where(seg_masks==3, 1.0, 0.0)\n",
        "        a_sum_pool = torch.sum(sequence_output * a_mask.unsqueeze(2).expand(-1, -1, self.d_model), 1)\n",
        "        a_mask_sum = a_sum_pool.sum(1)\n",
        "        a_mask_sum[a_mask_sum==0.0] = 1.0\n",
        "        a_avgpool = a_sum_pool / a_mask_sum.unsqueeze(1).expand(-1, self.d_model)\n",
        "\n",
        "\n",
        "        reg_input = torch.cat([t_avgpool, q_avgpool, a_avgpool, cls_output], dim=1)\n",
        "        probs = self.regressor(reg_input)\n",
        "        # print(probs.size())\n",
        "        # print('a', probs)\n",
        "        # print(labels.size())\n",
        "        # print('b', labels)\n",
        "        # input()\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = torch.nn.BCELoss()\n",
        "            # loss_fct = torch.nn.MSELoss()\n",
        "            loss = loss_fct(probs, labels)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (probs,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        SequenceRegressorOutput = namedtuple('SequenceRegressorOutput',\n",
        "                                             ['loss', 'probs', 'hidden_states', 'attentions'])\n",
        "        return SequenceRegressorOutput(\n",
        "            loss=loss,\n",
        "            probs=probs,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "    def freeze_decoder(self):\n",
        "        \"\"\"\n",
        "        Freeze XLNet weight parameters. They will not be updated during training.\n",
        "        \"\"\"\n",
        "        for param in self.distilbert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze_decoder(self):\n",
        "        \"\"\"\n",
        "        Freeze XLNet weight parameters. They will not be updated during training.\n",
        "        \"\"\"\n",
        "        for param in self.distilbert.parameters():\n",
        "            param.requires_grad = True\n",
        "    \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjnyGVV3K20e"
      },
      "source": [
        "# Define utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caaxlqjqZzne"
      },
      "source": [
        "from scipy.stats import spearmanr\n",
        "def compute_spearman(y_true, y_pred):\n",
        "  col = y_true.shape[1]\n",
        "  lst = []\n",
        "  for i in range(col):\n",
        "    # p = round(spearmanr(y_true[:, i], y_pred[:, i])[0], 5)\n",
        "    p = spearmanr(y_true[:, i], y_pred[:, i]).correlation\n",
        "    if np.isnan(p):\n",
        "      p = spearmanr(y_true[:, i], y_pred[:, i] + np.random.normal(0, 1e-7, y_pred.shape)).correlation\n",
        "    lst.append(p)\n",
        "  return np.array(lst), sum(lst)/len(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq-l9YdbvvGd"
      },
      "source": [
        "import gc\n",
        "def clear_mem(model_name='model'):\n",
        "    if model_name in locals():\n",
        "        print('deleting model...')\n",
        "        del model\n",
        "    for x in list(globals().keys()):\n",
        "        variable = eval(x)\n",
        "        if torch.is_tensor(variable) and variable.is_cuda:\n",
        "            print(x)\n",
        "            del variable\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-ClTZ_OVdfD"
      },
      "source": [
        "clear_mem()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lr76JaLijnH"
      },
      "source": [
        "def save_model(model, save_path, **metrics):\n",
        "    \"\"\"\n",
        "    Save the model to the path directory provided\n",
        "    \"\"\"\n",
        "    if \"state_dict\" in metrics:\n",
        "        raise Warning(\"We will use states from the model instead.\")\n",
        "        del metrics[\"state_dict\"]\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model\n",
        "    checkpoint = {'state_dict': model_to_save.state_dict()}\n",
        "    checkpoint.update(metrics)\n",
        "    torch.save(checkpoint, save_path)\n",
        "    return save_path, metrics\n",
        "\n",
        "def load_model(save_path, model=None):\n",
        "    \"\"\"\n",
        "    Load the model from the path directory provided\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        model = DistilBertForSequenceRegression.from_pretrained(pretrained_model)\n",
        "    checkpoint = torch.load(save_path)\n",
        "    model_state_dict = checkpoint['state_dict']\n",
        "    model.load_state_dict(model_state_dict)\n",
        "    metrics = {k:checkpoint[k] for k in checkpoint if k!='state_dict'}\n",
        "\n",
        "    return model, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dn46fXxK7QA"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKRlTJf8yPUx"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import tqdm.notebook as tqdm\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "\n",
        "def fold_train(model, train_data_loader, valid_data_loader, optimizer, max_epoch, lr_decay=0.1, clip=100.0, patience=1, fold_num=1):\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,patience=2, factor=lr_decay,verbose=True)\n",
        "    best_avg_valid_loss = float('inf')\n",
        "    best_spearmanr = float('-inf')\n",
        "    patience_count = patience\n",
        "    filepath = None\n",
        "    best_model_info = None\n",
        "    for epoch in tqdm.trange(max_epoch, desc=\"training\", unit=\"epoch\"):\n",
        "        total_loss = 0.0\n",
        "        final_avg_loss = 0.0\n",
        "        with tqdm.tqdm(train_data_loader,desc=\"epoch {} train\".format(epoch + 1),\n",
        "                  unit=\"batch\",total=len(train_data_loader)) as train_batch_iterator:\n",
        "            model.train()\n",
        "            for i, batch_data in enumerate(train_batch_iterator, start=1):\n",
        "                optimizer.zero_grad()\n",
        "                loss_data = model(input_ids=batch_data['input_sequence'],\n",
        "                                  attention_mask=batch_data['input_mask'],\n",
        "                                  labels=batch_data['target'],\n",
        "                                  seg_masks=batch_data['seg_mask'])\n",
        "                loss = loss_data.loss\n",
        "                total_loss += loss.item()\n",
        "                loss.backward()\n",
        "\n",
        "                # _ = nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "                optimizer.step()\n",
        "                train_batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item())\n",
        "                final_avg_loss = total_loss / i\n",
        "            scheduler.step(final_avg_loss)\n",
        "        total_valid_loss = 0.0\n",
        "        final_avg_valid_loss = 0.0\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            with tqdm.tqdm(valid_data_loader,desc=\"epoch {} valid\".format(epoch + 1),\n",
        "                      unit=\"batch\",total=len(valid_data_loader),leave=False) as valid_batch_iterator:\n",
        "                \n",
        "                for i, batch_data in enumerate(valid_batch_iterator, start=1):\n",
        "                    loss_data = model(input_ids=batch_data['input_sequence'],\n",
        "                                      attention_mask=batch_data['input_mask'],\n",
        "                                      labels=batch_data['target'],\n",
        "                                      seg_masks=batch_data['seg_mask'])\n",
        "                    loss = loss_data.loss\n",
        "                    total_valid_loss += loss.item()\n",
        "                    valid_batch_iterator.set_postfix(mean_loss=total_valid_loss / i, current_loss=loss.item())\n",
        "                    final_avg_valid_loss = total_valid_loss / i\n",
        "                    pred_labels.append(loss_data.probs.to('cpu').numpy())\n",
        "                    true_labels.append(batch_data['target'].to('cpu').numpy())\n",
        "        true_labels = np.concatenate(true_labels, axis=0)\n",
        "        pred_labels = np.concatenate(pred_labels, axis=0)\n",
        "        # print(true_labels.shape)\n",
        "        # print(pred_labels.shape)\n",
        "        sp_correlation = compute_spearman(pred_labels, true_labels)\n",
        "\n",
        "        np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "        # print(\"spearmanr scores:\", sp_correlation[0])\n",
        "        sorted_ind = np.argsort(sp_correlation[0])\n",
        "        sorted_labels = [target_cols[ind] for ind in sorted_ind]\n",
        "        print(\"predicted features from worst to best:\")\n",
        "        for r, (lb,sc) in enumerate(zip(sorted_labels, sp_correlation[0][sorted_ind])):\n",
        "            print(f\"\\t{r}. {lb}: {sc}\")\n",
        "        np.set_printoptions()\n",
        "\n",
        "        print(f\"Validation results for epoch #{epoch + 1}: average_loss={final_avg_valid_loss}, spearman_rho={sp_correlation[-1]}\")\n",
        "\n",
        "        # if final_avg_valid_loss > best_avg_valid_loss:\n",
        "        #     patience_count -= 1\n",
        "        # best_avg_valid_loss = min(final_avg_valid_loss, best_avg_valid_loss)\n",
        "        # if patience_count == 0:\n",
        "        #     print(\"Early Stopping: the average validation loss did not improve.\")\n",
        "        #     break\n",
        "\n",
        "        if sp_correlation[-1] < best_spearmanr:\n",
        "            patience_count -= 1\n",
        "        elif sp_correlation[-1] > best_spearmanr:\n",
        "            filepath = f\"./best_fold{fold_num}.pt\"\n",
        "            score_info = {'spearmanr':sp_correlation[-1],\n",
        "                          'train_loss':final_avg_loss,\n",
        "                          'valid_loss':final_avg_valid_loss,\n",
        "                          'epoch':epoch + 1}\n",
        "            print(\"Saving this model...\")\n",
        "            filepath, best_model_info = save_model(model, filepath,\n",
        "                                                   avg_valid_loss=final_avg_valid_loss,\n",
        "                                                   spearmanr_corr=sp_correlation[-1])\n",
        "            \n",
        "        best_spearmanr = max(sp_correlation[-1], best_spearmanr)\n",
        "        if patience_count == 0:\n",
        "            print(\"Early Stopping: the average spearmanr did not improve.\")\n",
        "            break\n",
        "    return filepath, best_model_info, score_info\n",
        "\n",
        "best_scores = []\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "epoch_best = []\n",
        "\n",
        "splits = 5\n",
        "kf = KFold(n_splits=splits, shuffle=True, random_state=42)\n",
        "max_epoch = 30\n",
        "fold_num = 1\n",
        "model_records = []\n",
        "device_used = None\n",
        "for train_index, valid_index in tqdm.tqdm(kf.split(df_train), desc=\"Cross Validation\", unit=\"fold\", total=splits):\n",
        "    print('Fold {} starting...'.format(fold_num))\n",
        "    clear_mem()\n",
        "    model = DistilBertForSequenceRegression.from_pretrained(pretrained_model)\n",
        "    # model.freeze_decoder()\n",
        "    model = model.cuda()\n",
        "    device_used = model.distilbert.embeddings.word_embeddings.weight.device\n",
        "    train_dataset = QUEST_DistilBert_Dataset(df_train.iloc[train_index], tokenizer, [64, 224, 224],\n",
        "                                          device=device_used)\n",
        "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn=train_dataset.collate_fn, shuffle=True)\n",
        "    valid_dataset = QUEST_DistilBert_Dataset(df_train.iloc[valid_index], tokenizer, [64, 224, 224],\n",
        "                                          device=device_used, training=True)\n",
        "    valid_data_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, collate_fn=valid_dataset.collate_fn, shuffle=False)\n",
        "\n",
        "    bert_param_names = ['distilbert']\n",
        "    bert_named_params = list(filter(lambda kv: any(key in kv[0] for key in bert_param_names), model.named_parameters()))\n",
        "    classifier_named_params = list(filter(lambda kv: not any(key in kv[0] for key in bert_param_names), model.named_parameters()))\n",
        "    bert_params = [e[1] for e in bert_named_params]\n",
        "    classifier_params = [e[1] for e in classifier_named_params]\n",
        "\n",
        "    optimizer = AdamW([{'params': bert_params}, {'params': classifier_params, 'lr': 1e-4}], lr=2e-5, weight_decay=0.01, betas=(0.5, 0.999), correct_bias=True)\n",
        "    filepath, best_model_info, score_info = fold_train(model, train_data_loader, valid_data_loader, optimizer, max_epoch, fold_num=fold_num)\n",
        "    best_scores.append(score_info['spearmanr'])\n",
        "    train_losses.append(score_info['train_loss'])\n",
        "    valid_losses.append(score_info['valid_loss'])\n",
        "    epoch_best.append(score_info['epoch'])\n",
        "    model_records.append((filepath, best_model_info['spearmanr_corr']))\n",
        "    clear_mem()\n",
        "    fold_num += 1\n",
        "\n",
        "print('spearmanr mean:', sum(best_scores)/len(best_scores))\n",
        "print('spearmanr max:', max(best_scores))\n",
        "print('spearmanr min:', min(best_scores))\n",
        "print('spearmanr std:', np.std(best_scores))\n",
        "print('avg train loss', sum(train_losses)/len(train_losses))\n",
        "print('avg valid loss', sum(valid_losses)/len(valid_losses))\n",
        "print('avg epoch for convergence', sum(epoch_best)/len(epoch_best))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nLe7f0WK-70"
      },
      "source": [
        "# Do inference on the testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT6L46Gy6oeO"
      },
      "source": [
        "# prepare testset\n",
        "test_dataset = QUEST_DistilBert_Dataset(df_test, tokenizer, [64, 224, 224],\n",
        "                                          device=device_used, training=False)\n",
        "test_data_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, collate_fn=test_dataset.collate_fn, shuffle=False)\n",
        "net_score = 0.0\n",
        "pred_unnormalized = []\n",
        "weights = []\n",
        "for model_path, spearmanr_score in model_records:\n",
        "    clear_mem()\n",
        "    model, info = load_model(model_path)\n",
        "    model.to(device_used)\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        with tqdm.tqdm(test_data_loader, unit=\"batch\",total=len(test_data_loader),leave=False) as test_batch_iterator:\n",
        "            \n",
        "            for i, batch_data in enumerate(test_batch_iterator, start=1):\n",
        "                output_data = model(input_ids=batch_data['input_sequence'],\n",
        "                                    attention_mask=batch_data['input_mask'],\n",
        "                                    seg_masks=batch_data['seg_mask'])\n",
        "                pred_labels.append(output_data.probs.to('cpu').numpy())\n",
        "    pred_labels = np.concatenate(pred_labels, axis=0)\n",
        "    weight = spearmanr_score\n",
        "    net_score += spearmanr_score\n",
        "    pred_unnormalized.append(pred_labels)\n",
        "    weights.append(weight)\n",
        "clear_mem()\n",
        "pred_unnormalized = np.array(pred_unnormalized)\n",
        "weights = np.array(weights) / net_score\n",
        "print(pred_unnormalized.shape)\n",
        "pred_final = np.einsum(\"ijk, i\", pred_unnormalized, weights)\n",
        "df_submit[target_cols] = pred_final\n",
        "df_submit.to_csv(\"submission.csv\", index = False)\n",
        "df_submit\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}